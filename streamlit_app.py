import time
import streamlit as st
from openai import OpenAI

# APIã‚­ãƒ¼ã‚’ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—ã—ã¦åˆæœŸåŒ–
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if "busy_until" not in st.session_state:
    st.session_state.busy_until = 0

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼æ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if "APP_PASSWORD" in st.secrets and not st.session_state.authenticated:
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if password == st.secrets["APP_PASSWORD"]:
            st.session_state.authenticated = True
            st.experimental_rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    st.stop()

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
st.title("ğŸ¤ Whisperæ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª")

audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["mp3","wav","m4a","mp4","webm","mpeg4"])
model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["whisper-1", "gpt-4o-mini-transcribe"])

def transcribe_once(file, model_name):
    now = time.time()
    # 1åˆ†ä»¥å†…ã¯ãƒ–ãƒ­ãƒƒã‚¯
    if now < st.session_state.busy_until:
        st.error("1åˆ†ä»¥å†…ã®é€£ç¶šå‘¼ã³å‡ºã—ã¯ç¦æ­¢ã§ã™ã€‚å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    st.session_state.busy_until = now + 60

    try:
        return client.audio.transcriptions.create(
            model=model_name,
            file=file,
            response_format="text"
        )
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

if audio and st.button("æ–‡å­—èµ·ã“ã—é–‹å§‹"):
    with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
        result = transcribe_once(audio, model)
    if result:
        st.text_area("æ–‡å­—èµ·ã“ã—çµæœ", result, height=300)
        st.download_button("ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜", result, file_name="transcript.txt")
