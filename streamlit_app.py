import time
import streamlit as st
from openai import OpenAI
import tempfile
import os

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if "busy_until" not in st.session_state:
    st.session_state.busy_until = 0

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
st.title("ğŸ¤ Whisperæ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª")

audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["mp3","wav","m4a","mp4","webm"])
model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["whisper-1", "gpt-4o-mini-transcribe"])

def transcribe_once(file, model_name):
    now = time.time()
    # 1åˆ†ä»¥å†…ã¯ãƒ–ãƒ­ãƒƒã‚¯
    if now < st.session_state.busy_until:
        st.error("1åˆ†ä»¥å†…ã®é€£ç¶šå‘¼ã³å‡ºã—ã¯ç¦æ­¢ã§ã™ã€‚å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    st.session_state.busy_until = now + 60

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
            tmp_file.write(file.getvalue())
            tmp_file_path = tmp_file.name

        st.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {tmp_file_path}")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦APIã«æ¸¡ã™
        with open(tmp_file_path, "rb") as audio_file:
            # APIã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if model_name == "gpt-4o-mini-transcribe":
                options = {
                    "model": model_name,
                    "file": audio_file,
                    "response_format": "text"  # ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã¦ç°¡æ˜“ãªå½¢å¼ã‚’ä½¿ç”¨
                }
            else:
                options = {
                    "model": model_name,
                    "file": audio_file,
                    "response_format": "text"  # ã¾ãšã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§è©¦ã™
                }
            
            result = client.audio.transcriptions.create(**options)
            
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.unlink(tmp_file_path)
        
        return result
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None

if audio and st.button("æ–‡å­—èµ·ã“ã—é–‹å§‹"):
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
    st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {audio.name if hasattr(audio, 'name') else 'ä¸æ˜'}")
    st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {audio.type if hasattr(audio, 'type') else 'ä¸æ˜'}")
    st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {audio.size if hasattr(audio, 'size') else 'ä¸æ˜'} bytes")
    
    with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
        result = transcribe_once(audio, model)
    
    if result:
        st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
        st.text_area("ãƒ†ã‚­ã‚¹ãƒˆ", result, height=300)
        st.download_button("ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜", result, file_name="transcript.txt")
