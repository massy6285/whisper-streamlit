import time
import streamlit as st
from openai import OpenAI
import tempfile
import os
from datetime import datetime
import json

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– - å±¥æ­´ä¿å­˜ç”¨
if "transcription_history" not in st.session_state:
    st.session_state.transcription_history = []

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ¤ Whisperæ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª")

# ã‚¿ãƒ–ä½œæˆ: æ–‡å­—èµ·ã“ã—ã¨å±¥æ­´
tab1, tab2 = st.tabs(["æ–‡å­—èµ·ã“ã—", "å±¥æ­´"])

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° - å…ˆã«å®šç¾©ã—ã¦ãŠã
def format_timestamp(seconds):
    """ç§’æ•°ã‚’ MM:SS.MS å½¢å¼ã«å¤‰æ›"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{minutes:02}:{secs:02}.{millisecs:03}"

# æ–‡å­—èµ·ã“ã—ã‚¿ãƒ–ã®å†…å®¹
with tab1:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    audio = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["mp3","wav","m4a","mp4","webm"])
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["whisper-1", "gpt-4o-mini-transcribe"])
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªè©³ç´°è¨­å®š
    show_timestamps = st.checkbox("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¡¨ç¤º", value=True)
    
    # éŸ³å£°ã®ç¨®é¡ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ï¼‰
    audio_context = st.selectbox("éŸ³å£°ã®å†…å®¹", [
        "æŒ‡å®šãªã—", 
        "è¬›æ¼”/ãƒ—ãƒ¬ã‚¼ãƒ³", 
        "ä¼šè­°/ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°", 
        "ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼",
        "æˆæ¥­/è¬›ç¾©",
        "å•†è«‡",
        "èª¬æ•™/ã‚¹ãƒ”ãƒ¼ãƒ"
    ])
    
    # å›ºæœ‰åè©
    proper_nouns = st.text_input("å›ºæœ‰åè©ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰", "")
    
    # æ–‡å­—èµ·ã“ã—é–¢æ•°ã®å®šç¾©
    def transcribe_audio(file, model_name, with_timestamps, context="", nouns=""):
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = ""
            if context != "æŒ‡å®šãªã—":
                prompt += f"ã“ã®éŸ³å£°ã¯{context}ã§ã™ã€‚"
            
            if nouns:
                nouns_list = [n.strip() for n in nouns.replace("ã€", ",").split(",") if n.strip()]
                if nouns_list:
                    prompt += f" æ¬¡ã®å›ºæœ‰åè©ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {', '.join(nouns_list)}ã€‚"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_file_path = tmp_file.name
            
            # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            progress = st.progress(30, text="æ–‡å­—èµ·ã“ã—ä¸­...")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦APIã«æ¸¡ã™
            with open(tmp_file_path, "rb") as audio_file:
                # APIã‚ªãƒ—ã‚·ãƒ§ãƒ³
                options = {
                    "model": model_name,
                    "file": audio_file
                }
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ ï¼ˆwhisper-1ã§ã®ã¿ä½¿ç”¨å¯èƒ½ï¼‰
                if with_timestamps and model_name == "whisper-1":
                    options["response_format"] = "verbose_json"
                    options["timestamp_granularities"] = ["segment"]
                else:
                    options["response_format"] = "text"
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ 
                if prompt:
                    options["prompt"] = prompt
                    st.info(f"ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
                
                progress.progress(60, text="OpenAI APIã«é€ä¿¡ä¸­...")
                result = client.audio.transcriptions.create(**options)
                
            # é€²æ—ã‚’æ›´æ–°
            progress.progress(100, text="å®Œäº†!")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_file_path)
            
            return result
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            return None
    
    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œãƒœã‚¿ãƒ³
    if audio and st.button("æ–‡å­—èµ·ã“ã—é–‹å§‹"):
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ - 25MBä»¥ä¸Šã¯è­¦å‘Šè¡¨ç¤º
        if audio.size > 25 * 1024 * 1024:  # 25MB
            st.warning("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚OpenAI APIã®åˆ¶é™ã«ã‚ˆã‚Šå‡¦ç†ã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«: {audio.name} ({audio.size} bytes)")
        
        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
        with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
            result = transcribe_audio(
                file=audio, 
                model_name=model, 
                with_timestamps=show_timestamps,
                context=audio_context,
                nouns=proper_nouns
            )
        
        if result:
            # çµæœè¡¨ç¤ºï¼ˆã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦åˆ†å²ï¼‰
            if isinstance(result, str):
                # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
                st.text_area("ãƒ†ã‚­ã‚¹ãƒˆ", result, height=300)
                plaintext = result
            elif hasattr(result, 'text'):
                # verbose_jsonå½¢å¼ã®å ´åˆ
                st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
                st.text_area("ãƒ†ã‚­ã‚¹ãƒˆ", result.text, height=200)
                plaintext = result.text
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¡¨ç¤ºï¼ˆä¿®æ­£éƒ¨åˆ†ï¼‰
                if hasattr(result, 'segments'):
                    st.subheader("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
                    for segment in result.segments:
                        try:
                            # segment ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ç›´æ¥å±æ€§ã«ã‚¢ã‚¯ã‚»ã‚¹
                            if hasattr(segment, 'start') and hasattr(segment, 'end') and hasattr(segment, 'text'):
                                start_time = format_timestamp(segment.start)
                                end_time = format_timestamp(segment.end)
                                segment_text = segment.text
                            # dict ã®å ´åˆ
                            elif isinstance(segment, dict):
                                start_time = format_timestamp(segment.get('start', 0))
                                end_time = format_timestamp(segment.get('end', 0))
                                segment_text = segment.get('text', '')
                            else:
                                start_time = "??:??"
                                end_time = "??:??"
                                segment_text = str(segment)
                                
                            st.markdown(f"**[{start_time} â†’ {end_time}]** {segment_text}")
                        except Exception as e:
                            st.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                            st.write(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…å®¹: {segment}")
            else:
                # ãã®ä»–ã®å½¢å¼ï¼ˆJSONæ–‡å­—åˆ—ãªã©ï¼‰
                st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
                if isinstance(result, dict) and 'text' in result:
                    plaintext = result['text']
                else:
                    plaintext = str(result)
                st.text_area("ãƒ†ã‚­ã‚¹ãƒˆ", plaintext, height=300)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", 
                plaintext, 
                file_name=f"æ–‡å­—èµ·ã“ã—_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            )
            
            # å±¥æ­´ã«ä¿å­˜
            st.session_state.transcription_history.append({
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "filename": audio.name,
                "text": plaintext[:5000]  # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            })
            st.success("çµæœã‚’å±¥æ­´ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

# å±¥æ­´ã‚¿ãƒ–ã®å†…å®¹
with tab2:
    st.header("æ–‡å­—èµ·ã“ã—å±¥æ­´")
    
    if not st.session_state.transcription_history:
        st.info("ã¾ã å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã“ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        # å±¥æ­´ã®è¡¨ç¤ºï¼ˆæ–°ã—ã„é †ï¼‰
        for i, item in enumerate(reversed(st.session_state.transcription_history)):
            with st.expander(f"{item['timestamp']} - {item['filename']}"):
                st.text_area(
                    "æ–‡å­—èµ·ã“ã—çµæœ", 
                    item["text"], 
                    height=200,
                    key=f"history_{i}"
                )
                st.download_button(
                    "ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜", 
                    item["text"], 
                    file_name=f"{item['filename']}_{item['timestamp']}.txt",
                    key=f"download_{i}"
                )
        
        # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.transcription_history = []
            st.experimental_rerun()
